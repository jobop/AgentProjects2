#!/usr/bin/env python3
"""
LLM-Driven Common Agent Server

çœŸæ­£çš„LLMé©±åŠ¨çš„Common Agentï¼Œè´Ÿè´£ï¼š
1. é€šè¿‡LLMåˆ†æä»»åŠ¡å¹¶å†³ç­–
2. åŠ¨æ€å‘ç°å¯ç”¨çš„specialist agents
3. ä½¿ç”¨A2Aåè®®ä¸agentsé€šä¿¡
4. è‡ªåŠ¨é€‰æ‹©å’Œä½¿ç”¨MCPå·¥å…·
5. åè°ƒå¤šagentåä½œå®Œæˆå¤æ‚ä»»åŠ¡

æ²¡æœ‰ä»»ä½•ç¡¬ç¼–ç é€»è¾‘ï¼Œå®Œå…¨ä¾èµ–LLMæ™ºèƒ½å†³ç­–
"""

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from fastapi import FastAPI
import uvicorn
import httpx
from datetime import datetime

# Add paths for imports
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))

from llm.client import LLMClient
from mcp.simple_mcp_loader import SimpleMCPLoader
from shared.config_manager import get_timeout, config_manager

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AgentDiscovery:
    """Agentå‘ç°å’Œç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.discovered_agents = {}
        self.agent_capabilities = {}
        
    async def discover_agents(self, discovery_endpoints: List[str]) -> Dict[str, Any]:
        """
        å‘ç°å¯ç”¨çš„agents
        
        Args:
            discovery_endpoints: agentå‘ç°ç«¯ç‚¹åˆ—è¡¨
            
        Returns:
            å‘ç°çš„agentsä¿¡æ¯
        """
        logger.info("ğŸ” å¼€å§‹agentå‘ç°è¿‡ç¨‹...")
        
        for endpoint in discovery_endpoints:
            try:
                await self._discover_single_agent(endpoint)
            except Exception as e:
                logger.warning(f"âš ï¸  å‘ç°agentå¤±è´¥ {endpoint}: {e}")
                
        logger.info(f"âœ… å‘ç°å®Œæˆï¼Œæ‰¾åˆ° {len(self.discovered_agents)} ä¸ªagents")
        return self.discovered_agents
    
    async def _discover_single_agent(self, endpoint: str):
        """å‘ç°å•ä¸ªagent"""
        async with httpx.AsyncClient() as client:
            # å°è¯•A2Aåè®®å‘ç°
            try:
                # æ£€æŸ¥ /a2a/agent.json (python-a2aæ ‡å‡†)
                response = await client.get(f"{endpoint}/a2a/agent.json", timeout=get_timeout("agent_discovery"))
                if response.status_code == 200:
                    agent_card = response.json()
                    agent_id = agent_card.get("name", "unknown").lower().replace(" ", "_")
                    self.discovered_agents[agent_id] = {
                        "endpoint": endpoint,
                        "agent_card": agent_card,
                        "protocol": "a2a",
                        "discovery_method": "agent_card"
                    }
                    self.agent_capabilities[agent_id] = agent_card.get("skills", [])
                    logger.info(f"   âœ… å‘ç°A2A agent: {agent_card.get('name')}")
                    return
            except:
                pass
                
            # å¤‡é€‰ï¼šæ£€æŸ¥ /.well-known/agent.json (A2Aæ ‡å‡†è·¯å¾„)
            try:
                response = await client.get(f"{endpoint}/.well-known/agent.json", timeout=get_timeout("agent_discovery"))
                if response.status_code == 200:
                    agent_card = response.json()
                    agent_id = agent_card.get("name", "unknown").lower().replace(" ", "_")
                    self.discovered_agents[agent_id] = {
                        "endpoint": endpoint,
                        "agent_card": agent_card,
                        "protocol": "a2a",
                        "discovery_method": "agent_card_standard"
                    }
                    self.agent_capabilities[agent_id] = agent_card.get("skills", [])
                    logger.info(f"   âœ… å‘ç°A2A agent (æ ‡å‡†è·¯å¾„): {agent_card.get('name')}")
                    return
            except:
                pass
                
            # å°è¯•ä¼ ç»Ÿèƒ½åŠ›ç«¯ç‚¹
            try:
                response = await client.get(f"{endpoint}/capabilities", timeout=get_timeout("agent_discovery"))
                if response.status_code == 200:
                    capabilities = response.json()
                    agent_name = capabilities.get("agent_name", "unknown")
                    agent_id = agent_name.lower().replace(" ", "_")
                    self.discovered_agents[agent_id] = {
                        "endpoint": endpoint,
                        "capabilities": capabilities,
                        "protocol": "legacy",
                        "discovery_method": "capabilities_endpoint"
                    }
                    self.agent_capabilities[agent_id] = capabilities.get("capabilities", [])
                    logger.info(f"   âœ… å‘ç°legacy agent: {agent_name}")
                    return
            except:
                pass
                
            # å°è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹
            try:
                response = await client.get(f"{endpoint}/health", timeout=get_timeout("health_check"))
                if response.status_code == 200:
                    health = response.json()
                    agent_name = health.get("agent", "unknown")
                    agent_id = agent_name.lower().replace(" ", "_")
                    self.discovered_agents[agent_id] = {
                        "endpoint": endpoint,
                        "health": health,
                        "protocol": "unknown",
                        "discovery_method": "health_check"
                    }
                    logger.info(f"   âœ… å‘ç°åŸºç¡€agent: {agent_name}")
                    return
            except:
                pass
                
        logger.warning(f"   âŒ æ— æ³•å‘ç°agent: {endpoint}")
    
    def get_available_agents(self) -> List[str]:
        """è·å–å¯ç”¨agentåˆ—è¡¨"""
        return list(self.discovered_agents.keys())
    
    def get_agent_capabilities(self, agent_id: str) -> List[str]:
        """è·å–agentèƒ½åŠ›"""
        return self.agent_capabilities.get(agent_id, [])
    
    def get_agent_info(self, agent_id: str) -> Optional[Dict[str, Any]]:
        """è·å–agentä¿¡æ¯"""
        return self.discovered_agents.get(agent_id)


class LLMDrivenCommonAgent:
    """LLMé©±åŠ¨çš„Common Agent"""
    
    def __init__(self, port: int = 8000):
        self.port = port
        self.app = FastAPI(title="LLM-Driven Common Agent", version="1.0.0")
        
        # æ ¸å¿ƒç»„ä»¶
        self.llm_client = None
        self.mcp_loader = SimpleMCPLoader()
        self.agent_discovery = AgentDiscovery()
        
        # ç³»ç»ŸçŠ¶æ€
        self.active_tasks = {}
        self.task_counter = 0
        
        # Agentå‘ç°é…ç½® (ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–)
        self.discovery_endpoints = [
            "http://localhost:8001",  # User Research Agent
            "http://localhost:8002",  # Product Manager Agent  
            "http://localhost:8003",  # UI Designer Agent
        ]
        
        # å®šæ—¶åˆ·æ–°é…ç½®
        self.discovery_refresh_interval = 30  # 30ç§’åˆ·æ–°ä¸€æ¬¡
        self.discovery_task = None
        
        # ç«‹å³åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self._init_llm_client()
        
        # è®¾ç½®è·¯ç”±
        from routes import CommonAgentRoutes
        self.routes = CommonAgentRoutes(self.app, self)
        
    def _init_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        try:
            from llm.provider_enhanced import EnhancedSiliconFlowProvider
            
            # ç®€åŒ–çš„LLMé…ç½®ç±»
            class SimpleLLMConfig:
                def __init__(self):
                    self.provider = "siliconflow"
                    self.model = "deepseek-ai/DeepSeek-V3"
                    self.api_key = os.getenv("SILICONFLOW_API_KEY", "sk-wqbnsqwforwydiznaqiluckllleiqrtffhzjmpxrcjciifle")
                    self.base_url = "https://api.siliconflow.cn/v1"
                    self.max_tokens = 4096
                    self.temperature = 0.7
            
            # åˆ›å»ºé…ç½®
            llm_config = SimpleLLMConfig()
            
            # åˆ›å»ºæä¾›è€…
            provider = EnhancedSiliconFlowProvider(
                api_key=llm_config.api_key,
                model=llm_config.model
            )
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.llm_client = LLMClient(llm_config, provider)
            logger.info("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ
        
    async def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        logger.info("ğŸ¯ åˆå§‹åŒ–LLMé©±åŠ¨çš„Common Agent...")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            from llm.provider_enhanced import EnhancedSiliconFlowProvider
            
            # ç®€åŒ–çš„LLMé…ç½®ç±»
            class SimpleLLMConfig:
                def __init__(self):
                    self.provider = "siliconflow"
                    self.model = "deepseek-ai/DeepSeek-V3"
                    self.api_key = os.getenv("SILICONFLOW_API_KEY", "sk-wqbnsqwforwydiznaqiluckllleiqrtffhzjmpxrcjciifle")
                    self.base_url = "https://api.siliconflow.cn/v1"
                    self.max_tokens = 4096
                    self.temperature = 0.7
            
            # åˆ›å»ºé…ç½®
            llm_config = SimpleLLMConfig()
            
            # åˆ›å»ºæä¾›è€…
            provider = EnhancedSiliconFlowProvider(
            api_key=llm_config.api_key,
            model=llm_config.model
        )
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.llm_client = LLMClient(llm_config, provider)
            logger.info("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # åˆå§‹åŒ–MCP
        try:
            self.mcp_loader.load_config()
            available_servers = self.mcp_loader.list_available_servers()
            logger.info(f"âœ… MCPåˆå§‹åŒ–æˆåŠŸï¼Œå¯ç”¨æœåŠ¡å™¨: {len(available_servers)}")
        except Exception as e:
            logger.warning(f"âš ï¸  MCPåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # å‘ç°agents
        await self.agent_discovery.discover_agents(self.discovery_endpoints)
        
        # å¯åŠ¨å®šæ—¶åˆ·æ–°ä»»åŠ¡
        self.discovery_task = asyncio.create_task(self._periodic_discovery_refresh())
        
        logger.info("ğŸ¯ Common Agentåˆå§‹åŒ–å®Œæˆ")
        
    async def _periodic_discovery_refresh(self):
        """å®šæ—¶åˆ·æ–°Agentå‘ç°"""
        logger.info(f"ğŸ”„ å¯åŠ¨å®šæ—¶Agentå‘ç°åˆ·æ–° (é—´éš”: {self.discovery_refresh_interval}ç§’)")
        
        while True:
            try:
                await asyncio.sleep(self.discovery_refresh_interval)
                
                logger.debug("ğŸ”„ æ‰§è¡Œå®šæ—¶Agentå‘ç°åˆ·æ–°...")
                previous_count = len(self.agent_discovery.discovered_agents)
                
                await self.agent_discovery.discover_agents(self.discovery_endpoints)
                
                current_count = len(self.agent_discovery.discovered_agents)
                
                if current_count != previous_count:
                    logger.info(f"ğŸ“Š Agentå‘ç°çŠ¶æ€æ›´æ–°: {previous_count} -> {current_count} ä¸ªAgent")
                else:
                    logger.debug(f"ğŸ“Š Agentå‘ç°çŠ¶æ€ç¨³å®š: {current_count} ä¸ªAgent")
                    
            except Exception as e:
                logger.error(f"âŒ å®šæ—¶Agentå‘ç°åˆ·æ–°å¤±è´¥: {e}")
                await asyncio.sleep(5)  # å‡ºé”™æ—¶ç­‰å¾…5ç§’åé‡è¯•
        

    
    async def process_task_with_llm_stream(self, task_id: str, task_data: Dict[str, Any]):
        """
        ä½¿ç”¨LLMæµå¼å¤„ç†ä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘
        
        å®Œå…¨ç”±LLMå†³å®šå¦‚ä½•å¤„ç†ä»»åŠ¡ï¼Œä½¿ç”¨SSEæµå¼å“åº”
        """
        description = task_data.get("description", "")
        task = self.active_tasks[task_id]
        
        logger.info(f"ğŸ§  LLMæµå¼åˆ†æä»»åŠ¡ {task_id}: {description}")
        
        # å‘é€åˆ†æå¼€å§‹äº‹ä»¶
        yield {"event": "llm_analysis_started", "task_id": task_id}
        
        # æ„å»ºç³»ç»Ÿä¸Šä¸‹æ–‡ç»™LLM
        system_context = await self._build_system_context()
        
        # LLMåˆ†ææç¤º
        analysis_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå¤šAgentç³»ç»Ÿçš„åè°ƒè€…ã€‚ç”¨æˆ·æäº¤äº†ä¸€ä¸ªä»»åŠ¡ï¼Œä½ éœ€è¦åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶å†³å®šå¦‚ä½•å¤„ç†ã€‚

å¯ç”¨çš„ç³»ç»Ÿèµ„æºï¼š
{json.dumps(system_context, indent=2, ensure_ascii=False)}

ç”¨æˆ·ä»»åŠ¡ï¼š
{description}

è¯·åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚ä½ çš„å›å¤å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
    "analysis": "å¯¹ä»»åŠ¡çš„è¯¦ç»†åˆ†æ",
    "execution_strategy": "single_agent|multi_agent|mcp_tools|hybrid",
    "required_agents": ["agent_idåˆ—è¡¨"],
    "required_tools": ["å·¥å…·åç§°åˆ—è¡¨"],
    "execution_plan": [
        {{
            "step": 1,
            "action": "agent_call|tool_use|coordination",
            "target": "agent_idæˆ–tool_name",
            "task": "å…·ä½“ä»»åŠ¡æè¿°",
            "dependencies": ["ä¾èµ–çš„å‰ç½®æ­¥éª¤"]
        }}
    ],
    "expected_deliverables": ["é¢„æœŸäº¤ä»˜ç‰©åˆ—è¡¨"]
}}

è¯·ç¡®ä¿ä½ çš„å†³ç­–å®Œå…¨åŸºäºå¯ç”¨çš„agentså’Œå·¥å…·ï¼Œä¸è¦å‡è®¾ä¸å­˜åœ¨çš„èƒ½åŠ›ã€‚
"""

        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            if not self.llm_client:
                yield {"event": "error", "error": "LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"}
                return
                
            # ä½¿ç”¨LLMæµå¼è·å–åˆ†æç»“æœ
            llm_response = ""
            logger.info("ğŸ” å¼€å§‹LLMæµå¼åˆ†æ...")
            
            async for chunk in self.llm_client.stream_message(message=analysis_prompt):
                llm_response += chunk
                # å‘é€LLMåˆ†æè¿›åº¦
                yield {"event": "llm_analysis_progress", "chunk": chunk}
            
            # å‘é€LLMåˆ†æå®Œæˆ
            yield {"event": "llm_analysis_completed", "analysis": llm_response}
            
            # è§£æLLMè¿”å›çš„JSON
            try:
                llm_decision = json.loads(llm_response)
            except json.JSONDecodeError:
                # å¦‚æœLLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                import re
                json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
                if json_match:
                    llm_decision = json.loads(json_match.group())
                else:
                    raise ValueError("LLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼")
            
            logger.info(f"ğŸ“‹ LLMå†³ç­–: {llm_decision['execution_strategy']}")
            
            # å‘é€LLMå†³ç­–äº‹ä»¶
            yield {"event": "llm_decision_made", "decision": llm_decision}
            
            # è®°å½•å†³ç­–æ­¥éª¤
            task["steps"].append({
                "step": "llm_analysis",
                "decision": llm_decision,
                "timestamp": datetime.now().isoformat()
            })
            
            # æ ¹æ®LLMå†³ç­–æµå¼æ‰§è¡Œä»»åŠ¡
            async for event in self._execute_llm_plan_stream(task_id, llm_decision):
                yield event
            
            # å®Œæˆä»»åŠ¡
            task["status"] = "completed"
            task["completed_at"] = datetime.now().isoformat()
            
            logger.info(f"âœ… LLMé©±åŠ¨ä»»åŠ¡ {task_id} å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ LLMä»»åŠ¡å¤„ç†å¤±è´¥: {e}")
            yield {"event": "error", "error": str(e)}
            
            # é™çº§å¤„ç†ï¼šå¦‚æœLLMå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é€»è¾‘
            async for event in self._fallback_processing_stream(task_id, description):
                yield event

    async def process_task_with_llm(self, task_id: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMå¤„ç†ä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘
        
        å®Œå…¨ç”±LLMå†³å®šå¦‚ä½•å¤„ç†ä»»åŠ¡ï¼Œæ— ä»»ä½•ç¡¬ç¼–ç é€»è¾‘
        """
        description = task_data.get("description", "")
        task = self.active_tasks[task_id]
        
        logger.info(f"ğŸ§  LLMåˆ†æä»»åŠ¡ {task_id}: {description}")
        
        # æ„å»ºç³»ç»Ÿä¸Šä¸‹æ–‡ç»™LLM
        system_context = await self._build_system_context()
        
        # LLMåˆ†ææç¤º
        analysis_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå¤šAgentç³»ç»Ÿçš„åè°ƒè€…ã€‚ç”¨æˆ·æäº¤äº†ä¸€ä¸ªä»»åŠ¡ï¼Œä½ éœ€è¦åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶å†³å®šå¦‚ä½•å¤„ç†ã€‚

å¯ç”¨çš„ç³»ç»Ÿèµ„æºï¼š
{json.dumps(system_context, indent=2, ensure_ascii=False)}

ç”¨æˆ·ä»»åŠ¡ï¼š
{description}

è¯·åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚ä½ çš„å›å¤å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
    "analysis": "å¯¹ä»»åŠ¡çš„è¯¦ç»†åˆ†æ",
    "execution_strategy": "single_agent|multi_agent|mcp_tools|hybrid",
    "required_agents": ["agent_idåˆ—è¡¨"],
    "required_tools": ["å·¥å…·åç§°åˆ—è¡¨"],
    "execution_plan": [
        {{
            "step": 1,
            "action": "agent_call|tool_use|coordination",
            "target": "agent_idæˆ–tool_name",
            "task": "å…·ä½“ä»»åŠ¡æè¿°",
            "dependencies": ["ä¾èµ–çš„å‰ç½®æ­¥éª¤"]
        }}
    ],
    "expected_deliverables": ["é¢„æœŸäº¤ä»˜ç‰©åˆ—è¡¨"]
}}

è¯·ç¡®ä¿ä½ çš„å†³ç­–å®Œå…¨åŸºäºå¯ç”¨çš„agentså’Œå·¥å…·ï¼Œä¸è¦å‡è®¾ä¸å­˜åœ¨çš„èƒ½åŠ›ã€‚
"""

        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            logger.info(f"ğŸ” æ£€æŸ¥LLMå®¢æˆ·ç«¯çŠ¶æ€: {self.llm_client is not None}")
            if not self.llm_client:
                raise ValueError("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯çš„å…·ä½“çŠ¶æ€
            logger.info(f"ğŸ” LLMå®¢æˆ·ç«¯ç±»å‹: {type(self.llm_client)}")
            logger.info(f"ğŸ” LLM Providerç±»å‹: {type(self.llm_client.provider) if self.llm_client else 'None'}")
            
            # æµ‹è¯•LLMè¿æ¥
            logger.info("ğŸ” å¼€å§‹æµ‹è¯•LLMè¿æ¥...")
            test_response = await self.llm_client.send_message("Hello, test connection")
            logger.info(f"ğŸ” LLMè¿æ¥æµ‹è¯•å“åº”: {repr(test_response[:100])}")
            
            # è®°å½•åˆ†ææç¤ºçš„é•¿åº¦å’Œå¼€å¤´
            logger.info(f"ğŸ” åˆ†ææç¤ºé•¿åº¦: {len(analysis_prompt)} å­—ç¬¦")
            logger.info(f"ğŸ” åˆ†ææç¤ºå¼€å¤´: {repr(analysis_prompt[:200])}")
            
            # è·å–LLMåˆ†æç»“æœ
            logger.info("ğŸ” å¼€å§‹è°ƒç”¨LLMè¿›è¡Œä»»åŠ¡åˆ†æ...")
            llm_response = await self.llm_client.send_message(
                message=analysis_prompt
            )
            
            logger.info(f"ğŸ” LLMåŸå§‹å“åº”é•¿åº¦: {len(llm_response)} å­—ç¬¦")
            logger.info(f"ğŸ” LLMå“åº”å‰200å­—ç¬¦: {repr(llm_response[:200])}")
            logger.info(f"ğŸ” LLMå“åº”å200å­—ç¬¦: {repr(llm_response[-200:])}")
            
            # æ£€æŸ¥LLMå“åº”æ˜¯å¦ä¸ºç©º
            if not llm_response or not llm_response.strip():
                logger.error("âŒ LLMè¿”å›ç©ºå“åº”")
                raise ValueError("LLMè¿”å›ç©ºå“åº”ï¼Œå¯èƒ½æ˜¯APIè°ƒç”¨å¤±è´¥")
            
            # ä½¿ç”¨å¢å¼ºçš„JSONè§£æå™¨
            logger.info("ğŸ” å¼€å§‹è§£æLLMå“åº”...")
            from core.json_parser import parse_decision_response
            llm_decision = parse_decision_response(llm_response)
            logger.info(f"ğŸ” è§£æç»“æœç±»å‹: {type(llm_decision)}")
            logger.info(f"ğŸ” è§£æç»“æœå†…å®¹: {llm_decision}")
            
            # ç¡®ä¿è¿”å›æ ¼å¼ç¬¦åˆé¢„æœŸ
            if not isinstance(llm_decision, dict):
                raise ValueError(f"LLMè¿”å›æ ¼å¼é”™è¯¯: {type(llm_decision)}")
            
            logger.info(f"ğŸ“‹ LLMå†³ç­–: {llm_decision['execution_strategy']}")
            
            # è®°å½•å†³ç­–æ­¥éª¤
            task["steps"].append({
                "step": "llm_analysis",
                "decision": llm_decision,
                "timestamp": datetime.now().isoformat()
            })
            
            # æ ¹æ®LLMå†³ç­–æ‰§è¡Œä»»åŠ¡
            result = await self._execute_llm_plan(task_id, llm_decision)
            
            # å®Œæˆä»»åŠ¡
            task["status"] = "completed"
            task["completed_at"] = datetime.now().isoformat()
            task["result"] = result
            
            logger.info(f"âœ… LLMé©±åŠ¨ä»»åŠ¡ {task_id} å®Œæˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ LLMä»»åŠ¡å¤„ç†å¤±è´¥: {e}")
            
            # é™çº§å¤„ç†ï¼šå¦‚æœLLMå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é€»è¾‘
            return await self._fallback_processing(task_id, description)
    
    async def _build_system_context(self) -> Dict[str, Any]:
        """æ„å»ºç³»ç»Ÿä¸Šä¸‹æ–‡ç»™LLM"""
        
        # å¯ç”¨agentsä¿¡æ¯
        available_agents = {}
        for agent_id in self.agent_discovery.get_available_agents():
            agent_info = self.agent_discovery.get_agent_info(agent_id)
            if agent_info:  # ç¡®ä¿agent_infoä¸ä¸ºNone
                available_agents[agent_id] = {
                    "endpoint": agent_info["endpoint"],
                    "capabilities": self.agent_discovery.get_agent_capabilities(agent_id),
                    "protocol": agent_info.get("protocol", "unknown")
                }
        
        # å¯ç”¨MCPå·¥å…· - æ·»åŠ è¯¦ç»†æ—¥å¿—
        available_tools = []
        mcp_server_details = []
        
        logger.info("ğŸ” æ„å»ºMCPå·¥å…·ä¸Šä¸‹æ–‡...")
        
        try:
            mcp_servers = self.mcp_loader.list_available_servers()
            logger.info(f"ğŸ”§ å‘ç° {len(mcp_servers)} ä¸ªMCPæœåŠ¡å™¨: {mcp_servers}")
            
            for server in mcp_servers:
                try:
                    # ä»é…ç½®è·å–æœåŠ¡å™¨ä¿¡æ¯
                    server_config = self.mcp_loader.get_server_config(server)
                    if server_config:
                        description = server_config.get("description", "No description")
                        command = server_config.get("command", "Unknown")
                        
                        logger.info(f"ğŸ“‹ {server} æœåŠ¡å™¨: {description} (å‘½ä»¤: {command})")
                        
                        # ç”±äºå·¥å…·éœ€è¦è¿è¡Œæ—¶å‘ç°ï¼Œè¿™é‡Œåªè®°å½•æœåŠ¡å™¨ä¿¡æ¯
                        mcp_server_details.append({
                            "name": server,
                            "description": description,
                            "command": command,
                            "tools": "éœ€è¦è¿è¡Œæ—¶å‘ç°"
                        })
                        
                        # æ·»åŠ ä¸€ä¸ªå ä½ç¬¦å·¥å…·ä¿¡æ¯
                        tool_info = {
                            "server": server,
                            "tool": "runtime_discovery",
                            "full_name": f"{server}:runtime_discovery",
                            "description": f"å·¥å…·éœ€è¦è¿è¡Œæ—¶ä» {server} æœåŠ¡å™¨å‘ç°"
                        }
                        available_tools.append(tool_info)
                    else:
                        logger.warning(f"âš ï¸  æœªæ‰¾åˆ° {server} çš„é…ç½®ä¿¡æ¯")
                        
                except Exception as e:
                    logger.error(f"âŒ è·å– {server} å·¥å…·ä¿¡æ¯å¤±è´¥: {e}")
                    
        except Exception as e:
            logger.error(f"âŒ MCPå·¥å…·ä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥: {e}")
        
        logger.info(f"ğŸ¯ MCPå·¥å…·ä¸Šä¸‹æ–‡å®Œæˆ: {len(available_tools)} ä¸ªå·¥å…·æ¥è‡ª {len(mcp_server_details)} ä¸ªæœåŠ¡å™¨")
        
        context = {
            "available_agents": available_agents,
            "available_mcp_tools": available_tools,
            "mcp_server_details": mcp_server_details,
            "total_agents": len(available_agents),
            "total_tools": len(available_tools)
        }
        
        # è®°å½•å®Œæ•´ä¸Šä¸‹æ–‡ç”¨äºè°ƒè¯•
        logger.info(f"ğŸ” å®Œæ•´ç³»ç»Ÿä¸Šä¸‹æ–‡: {json.dumps(context, indent=2, ensure_ascii=False)}")
        
        return context
    
    async def _execute_llm_plan_stream(self, task_id: str, llm_decision: Dict[str, Any]):
        """æµå¼æ‰§è¡ŒLLMåˆ¶å®šçš„è®¡åˆ’"""
        
        execution_plan = llm_decision.get("execution_plan", [])
        strategy = llm_decision.get("execution_strategy", "unknown")
        
        logger.info(f"ğŸ¯ æµå¼æ‰§è¡ŒLLMè®¡åˆ’: {strategy}, {len(execution_plan)} æ­¥")
        
        yield {"event": "execution_started", "strategy": strategy, "total_steps": len(execution_plan)}
        
        execution_results = []
        start_time = datetime.now()
        
        for step in execution_plan:
            step_num = step.get("step", 0)
            action = step.get("action", "unknown")
            target = step.get("target", "")
            task_desc = step.get("task", "")
            
            logger.info(f"ğŸ“ æ‰§è¡Œæ­¥éª¤ {step_num}: {action} -> {target}")
            
            # å‘é€æ­¥éª¤å¼€å§‹äº‹ä»¶
            yield {
                "event": "step_started", 
                "step_number": step_num,
                "step_description": f"{action} -> {target}: {task_desc}",
                "action": action, 
                "target": target,
                "task": task_desc
            }
            
            # æ·»åŠ å°å»¶è¿Ÿï¼Œè®©æµå¼è¾“å‡ºæ›´æ˜æ˜¾
            await asyncio.sleep(0.1)
            
            step_start_time = datetime.now()
            
            try:
                if action == "agent_call":
                    # å‘é€Agentè°ƒç”¨å¼€å§‹äº‹ä»¶
                    yield {"event": "agent_call_started", "agent_id": target}
                    
                    # è°ƒç”¨Agent
                    result = await self._call_agent(target, task_desc, execution_results)
                    
                    # å‘é€Agentè°ƒç”¨å®Œæˆäº‹ä»¶
                    success = result.get("success", True) if isinstance(result, dict) else True
                    duration = (datetime.now() - step_start_time).total_seconds() * 1000
                    yield {
                        "event": "agent_call_completed", 
                        "agent_id": target,
                        "result": result,
                        "duration": duration
                    }
                    
                    # æ·»åŠ å°å»¶è¿Ÿï¼Œè®©æµå¼è¾“å‡ºæ›´æ˜æ˜¾
                    await asyncio.sleep(0.05)
                    
                elif action == "tool_use":
                    # å‘é€MCPå·¥å…·ä½¿ç”¨äº‹ä»¶
                    yield {"event": "mcp_tool_used", "tool": target}
                    
                    result = await self._use_mcp_tool(target, task_desc)
                    
                elif action == "coordination":
                    result = await self._coordinate_action(target, task_desc, execution_results)
                else:
                    result = {"error": f"Unknown action: {action}"}
                
                step_duration = (datetime.now() - step_start_time).total_seconds() * 1000
                
                execution_results.append({
                    "step": step_num,
                    "action": action,
                    "target": target,
                    "result": result,
                    "duration": step_duration,
                    "timestamp": datetime.now().isoformat()
                })
                
                # å‘é€æ­¥éª¤å®Œæˆäº‹ä»¶ï¼ˆå¯¹äºéagent_callçš„æƒ…å†µï¼‰
                if action != "agent_call":
                    success = result.get("success", True) if isinstance(result, dict) else True
                    yield {
                        "event": "step_completed", 
                        "step_number": step_num,
                        "action": action,
                        "target": target,
                        "success": success,
                        "duration": step_duration,
                        "result": result
                    }
                
                # æ›´æ–°ä»»åŠ¡æ­¥éª¤
                self.active_tasks[task_id]["steps"].append({
                    "step": f"execution_step_{step_num}",
                    "action": action,
                    "target": target,
                    "result": result,
                    "duration": step_duration,
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"âŒ æ­¥éª¤ {step_num} æ‰§è¡Œå¤±è´¥: {e}")
                step_duration = (datetime.now() - step_start_time).total_seconds() * 1000
                
                error_result = {"error": str(e), "step": step_num}
                execution_results.append({
                    "step": step_num,
                    "action": action,
                    "target": target,
                    "result": error_result,
                    "duration": step_duration,
                    "timestamp": datetime.now().isoformat()
                })
                
                # å‘é€æ­¥éª¤å¤±è´¥äº‹ä»¶
                yield {
                    "event": "step_completed", 
                    "step_number": step_num,
                    "action": action,
                    "target": target,
                    "success": False,
                    "duration": step_duration,
                    "error": str(e)
                }
                
                # æ›´æ–°ä»»åŠ¡æ­¥éª¤
                self.active_tasks[task_id]["steps"].append({
                    "step": f"execution_step_{step_num}",
                    "action": action,
                    "target": target,
                    "result": error_result,
                    "duration": step_duration,
                    "timestamp": datetime.now().isoformat()
                })
        
        # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
        total_duration = (datetime.now() - start_time).total_seconds() * 1000
        
        # å‘é€æ‰§è¡Œå®Œæˆäº‹ä»¶
        yield {
            "event": "execution_completed",
            "total_steps": len(execution_plan),
            "successful_steps": len([r for r in execution_results if r.get("result", {}).get("success", True)]),
            "failed_steps": len([r for r in execution_results if not r.get("result", {}).get("success", True)]),
            "total_duration": total_duration,
            "results": execution_results
        }

    async def _fallback_processing_stream(self, task_id: str, description: str):
        """æµå¼é™çº§å¤„ç†"""
        yield {"event": "fallback_started", "reason": "LLMå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨é™çº§é€»è¾‘"}
        
        # ç®€å•çš„é™çº§é€»è¾‘ï¼šå¦‚æœåŒ…å«"è®¾è®¡"å…³é”®è¯ï¼Œè°ƒç”¨UIè®¾è®¡å¸ˆ
        if "è®¾è®¡" in description or "ç•Œé¢" in description or "UI" in description:
            yield {"event": "fallback_decision", "target": "ui_designer_agent", "reason": "æ£€æµ‹åˆ°è®¾è®¡ç›¸å…³ä»»åŠ¡"}
            
            try:
                result = await self._call_agent("ui_designer_agent", description, [])
                yield {"event": "fallback_completed", "result": result}
            except Exception as e:
                yield {"event": "fallback_error", "error": str(e)}
        else:
            yield {"event": "fallback_error", "error": "æ— æ³•ç¡®å®šåˆé€‚çš„å¤„ç†æ–¹å¼"}

    async def _execute_llm_plan(self, task_id: str, llm_decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒLLMåˆ¶å®šçš„è®¡åˆ’"""
        
        execution_plan = llm_decision.get("execution_plan", [])
        strategy = llm_decision.get("execution_strategy", "unknown")
        
        logger.info(f"ğŸ¯ æ‰§è¡ŒLLMè®¡åˆ’: {strategy}, {len(execution_plan)} æ­¥")
        
        execution_results = []
        
        for step in execution_plan:
            step_num = step.get("step", 0)
            action = step.get("action", "unknown")
            target = step.get("target", "")
            task_desc = step.get("task", "")
            
            logger.info(f"ğŸ“ æ‰§è¡Œæ­¥éª¤ {step_num}: {action} -> {target}")
            
            try:
                if action == "agent_call":
                    result = await self._call_agent(target, task_desc, execution_results)
                elif action == "tool_use":
                    result = await self._use_mcp_tool(target, task_desc)
                elif action == "coordination":
                    result = await self._coordinate_action(target, task_desc, execution_results)
                else:
                    result = {"error": f"Unknown action: {action}"}
                
                execution_results.append({
                    "step": step_num,
                    "action": action,
                    "target": target,
                    "result": result,
                    "timestamp": datetime.now().isoformat()
                })
                
                # æ›´æ–°ä»»åŠ¡æ­¥éª¤
                self.active_tasks[task_id]["steps"].append({
                    "step": f"execution_step_{step_num}",
                    "action": action,
                    "target": target,
                    "result": result,
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"âŒ æ­¥éª¤ {step_num} æ‰§è¡Œå¤±è´¥: {e}")
                execution_results.append({
                    "step": step_num,
                    "action": action,
                    "target": target,
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
        
        # è¿”å›æ‰§è¡Œç»“æœ
        return {
            "task_id": task_id,
            "execution_strategy": strategy,
            "llm_decision": llm_decision,
            "execution_results": execution_results,
            "total_steps": len(execution_plan),
            "completed_steps": len(execution_results),
            "summary": self._generate_execution_summary(llm_decision, execution_results)
        }
    
    async def _call_agent(self, agent_id: str, task_description: str, previous_results: List[Dict]) -> Dict[str, Any]:
        """è°ƒç”¨specialist agent"""
        
        agent_info = self.agent_discovery.get_agent_info(agent_id)
        if not agent_info:
            return {"error": f"Agent not found: {agent_id}"}
        
        endpoint = agent_info["endpoint"]
        protocol = agent_info.get("protocol", "unknown")
        
        logger.info(f"ğŸ“ è°ƒç”¨ {agent_id} ({protocol}) : {task_description}")
        
        try:
            # æ„å»ºä»»åŠ¡æ•°æ®
            task_data = {
                "type": "delegated_task",
                "description": task_description,
                "context": {
                    "previous_results": previous_results,
                    "delegated_by": "common_agent"
                }
            }
            
            # æ ¹æ®åè®®ç±»å‹è°ƒç”¨
            if protocol == "a2a":
                return await self._call_a2a_agent(endpoint, task_data)
            else:
                return await self._call_legacy_agent(endpoint, task_data)
                
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨agent {agent_id} å¤±è´¥: {e}")
            return {"error": str(e), "agent": agent_id}
    
    async def _call_a2a_agent(self, endpoint: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨A2Aåè®®è°ƒç”¨agent"""
        
        # A2A JSON-RPC 2.0 è¯·æ±‚
        a2a_request = {
            "jsonrpc": "2.0",
            "method": "tasks/send",
            "id": f"common_agent_{int(datetime.now().timestamp())}",
            "params": {
                "id": f"task_{int(datetime.now().timestamp())}",
                "sessionId": f"session_{int(datetime.now().timestamp())}",
                "message": {
                    "role": "user",
                    "parts": [
                        {
                            "type": "text",
                            "text": task_data["description"]
                        },
                        {
                            "type": "data",
                            "data": task_data.get("context", {})
                        }
                    ]
                },
                "acceptedOutputModes": ["text", "application/json"]
            }
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{endpoint}/tasks/send",
                json=a2a_request,
                headers={"Content-Type": "application/json"},
                timeout=get_timeout("agent_communication")
            )
            
            if response.status_code == 200:
                result = response.json()
                if "result" in result:
                    return {"success": True, "result": result["result"], "protocol": "a2a"}
                else:
                    return {"error": "No result in A2A response", "response": result}
            else:
                return {"error": f"A2A call failed: HTTP {response.status_code}", "response": response.text}
    
    async def _call_legacy_agent(self, endpoint: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨legacyåè®®è°ƒç”¨agent"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{endpoint}/task",
                json=task_data,
                timeout=get_timeout("agent_communication")
            )
            
            if response.status_code == 200:
                result = response.json()
                return {"success": True, "result": result, "protocol": "legacy"}
            else:
                return {"error": f"Legacy call failed: HTTP {response.status_code}", "response": response.text}
    
    async def _use_mcp_tool(self, tool_name: str, task_description: str) -> Dict[str, Any]:
        """ä½¿ç”¨MCPå·¥å…· - çœŸæ­£çš„LLMå†³ç­–è°ƒç”¨å®ç°"""
        
        logger.info(f"ğŸ”§ ä½¿ç”¨MCPå·¥å…·: {tool_name} - {task_description}")
        
        try:
            # è§£æå·¥å…·åç§°å’ŒæœåŠ¡å™¨
            if ":" in tool_name:
                server_name, actual_tool = tool_name.split(":", 1)
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šæœåŠ¡å™¨ï¼Œå°è¯•ä»å·¥å…·åæ¨æ–­
                server_name = await self._infer_server_from_tool(tool_name)
                actual_tool = tool_name
            
            logger.info(f"ğŸ¯ è°ƒç”¨ {server_name} æœåŠ¡å™¨çš„ {actual_tool} å·¥å…·")
            
            # ğŸ¯ å®ç°çœŸæ­£çš„MCPå·¥å…·è°ƒç”¨
            # åŸºäºå·¥å…·ç±»å‹å’Œä»»åŠ¡æè¿°ç”Ÿæˆåˆé€‚çš„å‚æ•°
            tool_result = await self._execute_mcp_tool(server_name, actual_tool, task_description)
            
            return {
                "success": True,
                "server": server_name,
                "tool": actual_tool,
                "result": tool_result,
                "task_description": task_description,
                "execution_method": "LLM_driven_MCP_call"
            }
            
        except Exception as e:
            logger.error(f"âŒ MCPå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e), 
                "tool": tool_name,
                "task_description": task_description
            }
    
    async def _infer_server_from_tool(self, tool_name: str) -> str:
        """çœŸæ­£åŠ¨æ€æ¨æ–­MCPæœåŠ¡å™¨ - å®Œå…¨åŸºäºè¿è¡Œæ—¶å‘ç°ï¼Œæ— ç¡¬ç¼–ç """
        
        logger.debug(f"ğŸ” åŠ¨æ€æ¨æ–­å·¥å…· {tool_name} å¯¹åº”çš„MCPæœåŠ¡å™¨...")
        
        # ğŸ¯ çœŸæ­£çš„åŠ¨æ€å‘ç° - éå†æ‰€æœ‰å¯ç”¨æœåŠ¡å™¨æŸ¥æ‰¾å·¥å…·
        try:
            available_servers = self.mcp_loader.list_available_servers()
            
            for server_name in available_servers:
                # åŠ¨æ€æŸ¥è¯¢æ¯ä¸ªæœåŠ¡å™¨çš„å·¥å…·åˆ—è¡¨
                server_tools = await self._query_mcp_server_tools_runtime(server_name)
                
                if tool_name in server_tools:
                    logger.info(f"ğŸ¯ åœ¨ {server_name} æœåŠ¡å™¨ä¸­æ‰¾åˆ°å·¥å…· {tool_name}")
                    return server_name
            
            logger.warning(f"âš ï¸  æœªåœ¨ä»»ä½•MCPæœåŠ¡å™¨ä¸­æ‰¾åˆ°å·¥å…·: {tool_name}")
            return "unknown"
            
        except Exception as e:
            logger.error(f"âŒ åŠ¨æ€å·¥å…·æ¨æ–­å¤±è´¥: {e}")
            return "unknown"
    
    async def _query_mcp_server_tools_runtime(self, server_name: str) -> List[str]:
        """è¿è¡Œæ—¶æŸ¥è¯¢MCPæœåŠ¡å™¨çš„çœŸå®å·¥å…·åˆ—è¡¨"""
        
        try:
            # ğŸ¯ ä½¿ç”¨çœŸæ­£çš„MCPåè®®å®¢æˆ·ç«¯
            from mcp.mcp_protocol_client import mcp_client
            
            logger.debug(f"ğŸ”§ è¿è¡Œæ—¶æŸ¥è¯¢ {server_name} çš„å·¥å…·åˆ—è¡¨")
            
            # è·å–æœåŠ¡å™¨é…ç½®
            server_configs = self.mcp_loader.servers_config
            server_config = server_configs.get(server_name)
            
            if not server_config:
                logger.warning(f"âš ï¸  MCPæœåŠ¡å™¨ {server_name} é…ç½®æœªæ‰¾åˆ°")
                return []
            
            # é€šè¿‡MCPåè®®å‘ç°å·¥å…·
            tools = await mcp_client.discover_tools(server_name, server_config)
            tool_names = [tool.get('name', '') for tool in tools if tool.get('name')]
            
            logger.debug(f"ğŸ” è¿è¡Œæ—¶å‘ç° {server_name} çš„ {len(tool_names)} ä¸ªå·¥å…·")
            return tool_names
            
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œæ—¶MCPå·¥å…·æŸ¥è¯¢å¤±è´¥ {server_name}: {e}")
            return []
    
    async def _execute_mcp_tool(self, server_name: str, tool_name: str, task_description: str) -> Dict[str, Any]:
        """çœŸæ­£æ‰§è¡ŒMCPå·¥å…· - æ— ç¡¬ç¼–ç ï¼Œå®Œå…¨åŠ¨æ€è°ƒç”¨"""
        
        logger.info(f"ğŸ¯ æ‰§è¡ŒMCPå·¥å…·: {server_name}:{tool_name}")
        logger.debug(f"   ä»»åŠ¡æè¿°: {task_description}")
        
        try:
            # ğŸ¯ å®ç°çœŸæ­£çš„MCPåè®®å·¥å…·è°ƒç”¨
            result = await self._invoke_mcp_tool_via_protocol(server_name, tool_name, task_description)
            
            return {
                "success": True,
                "server": server_name,
                "tool": tool_name,
                "task_description": task_description,
                "execution_method": "real_mcp_protocol",
                "result": result
            }
            
        except Exception as e:
            logger.error(f"âŒ MCPå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "server": server_name,
                "tool": tool_name,
                "task_description": task_description,
                "error": str(e),
                "note": "MCPå·¥å…·è°ƒç”¨éœ€è¦çœŸæ­£çš„MCPåè®®å®ç°"
            }
    
    async def _invoke_mcp_tool_via_protocol(self, server_name: str, tool_name: str, task_description: str) -> Dict[str, Any]:
        """é€šè¿‡MCPåè®®çœŸæ­£è°ƒç”¨å·¥å…· - æ— ä»»ä½•ç¡¬ç¼–ç å‡è®¾"""
        
        # ğŸ¯ TODO: å®ç°çœŸæ­£çš„MCPå·¥å…·è°ƒç”¨åè®®
        # 
        # çœŸæ­£çš„å®ç°åº”è¯¥ï¼š
        # 1. è¿æ¥åˆ°æŒ‡å®šçš„MCPæœåŠ¡å™¨
        # 2. å‘é€JSON-RPC 2.0 call_toolè¯·æ±‚
        # 3. ä¼ é€’å·¥å…·åç§°å’Œæ ¹æ®ä»»åŠ¡æè¿°ç”Ÿæˆçš„å‚æ•°
        # 4. è¿”å›æœåŠ¡å™¨çš„å®é™…æ‰§è¡Œç»“æœ
        #
        # å½“å‰é˜¶æ®µï¼šè¿”å›å ä½ç¬¦ç»“æœï¼Œé¿å…ä»»ä½•ç¡¬ç¼–ç é€»è¾‘
        
        logger.debug(f"ğŸ”§ éœ€è¦é€šè¿‡MCPåè®®è°ƒç”¨ {server_name}:{tool_name}")
        
        return {
            "status": "mcp_protocol_required",
            "message": f"éœ€è¦å®ç°çœŸæ­£çš„MCPåè®®æ¥è°ƒç”¨ {tool_name}",
            "server": server_name,
            "tool": tool_name,
            "task": task_description,
            "note": "çœŸæ­£çš„MCPè¿æ¥å®ç°åï¼Œè¿™é‡Œä¼šè¿”å›å·¥å…·çš„å®é™…æ‰§è¡Œç»“æœ"
        }
    
    async def _coordinate_action(self, target: str, description: str, previous_results: List[Dict]) -> Dict[str, Any]:
        """åè°ƒåŠ¨ä½œ"""
        
        logger.info(f"ğŸ”„ åè°ƒåŠ¨ä½œ: {target}")
        
        # è¿™é‡Œå¯ä»¥å®ç°å¤æ‚çš„åè°ƒé€»è¾‘
        # ä¾‹å¦‚åˆå¹¶å¤šä¸ªagentçš„ç»“æœï¼Œæˆ–è€…è¿›è¡Œåå¤„ç†
        
        return {
            "success": True,
            "coordination_target": target,
            "description": description,
            "result": "åè°ƒåŠ¨ä½œå®Œæˆ",
            "processed_results": len(previous_results)
        }
    
    def _generate_execution_summary(self, llm_decision: Dict[str, Any], execution_results: List[Dict]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ€»ç»“"""
        
        successful_steps = sum(1 for r in execution_results if "error" not in r)
        total_steps = len(execution_results)
        
        return f"LLMé©±åŠ¨çš„ä»»åŠ¡æ‰§è¡Œå®Œæˆã€‚ç­–ç•¥: {llm_decision.get('execution_strategy', 'unknown')}, æˆåŠŸæ­¥éª¤: {successful_steps}/{total_steps}"
    
    async def _fallback_processing(self, task_id: str, description: str) -> Dict[str, Any]:
        """é™çº§å¤„ç†ï¼šå½“LLMå¤±è´¥æ—¶çš„åŸºç¡€å¤„ç†"""
        
        logger.warning(f"âš ï¸  LLMå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨é™çº§å¤„ç†")
        
        # éå¸¸åŸºç¡€çš„é™çº§é€»è¾‘
        available_agents = self.agent_discovery.get_available_agents()
        
        if available_agents:
            # éšæœºé€‰æ‹©ä¸€ä¸ªå¯ç”¨agent
            selected_agent = available_agents[0]
            logger.info(f"ğŸ² é™çº§é€‰æ‹©agent: {selected_agent}")
            
            result = await self._call_agent(selected_agent, description, [])
            
            return {
                "task_id": task_id,
                "execution_strategy": "fallback",
                "selected_agent": selected_agent,
                "result": result,
                "note": "ä½¿ç”¨é™çº§å¤„ç†ï¼Œå› ä¸ºLLMåˆ†æå¤±è´¥"
            }
        else:
            return {
                "task_id": task_id,
                "execution_strategy": "failed",
                "error": "æ²¡æœ‰å¯ç”¨çš„agentsï¼Œä¸”LLMå¤„ç†å¤±è´¥",
                "available_agents": available_agents
            }
    
    async def start(self):
        """å¯åŠ¨Common AgentæœåŠ¡å™¨"""
        logger.info(f"ğŸ¯ å¯åŠ¨LLMé©±åŠ¨çš„Common AgentæœåŠ¡å™¨ (ç«¯å£ {self.port})...")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        await self.initialize()
        
        # è®°å½•è¶…æ—¶é…ç½®ä¿¡æ¯
        config_manager.log_timeout_info()
        
        # å¯åŠ¨HTTPæœåŠ¡å™¨
        config = uvicorn.Config(
            app=self.app,
            host="0.0.0.0",
            port=self.port,
            log_level="info"
        )
        
        server = uvicorn.Server(config)
        await server.serve()


async def main():
    """ä¸»å‡½æ•°"""
    port = int(os.environ.get("AGENT_PORT", 8000))
    
    server = LLMDrivenCommonAgent(port=port)
    await server.start()


if __name__ == "__main__":
    asyncio.run(main()) 