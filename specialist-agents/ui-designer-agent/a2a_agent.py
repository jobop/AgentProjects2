#!/usr/bin/env python3
"""
çœŸæ­£çš„UIè®¾è®¡å¸ˆAgent

å‚è€ƒcommon agentçš„MCPç®¡ç†æ–¹å¼ï¼Œä»mcp_servers.jsonè¯»å–çœŸå®é…ç½®
è®©LLMæ ¹æ®çœŸå®å¯ç”¨çš„MCPå·¥å…·å†³ç­–ä½¿ç”¨å“ªäº›å·¥å…·è¿›è¡Œè®¾è®¡
"""

import asyncio
import json
import logging
import os
import sys
import httpx
from typing import Dict, Any, Optional, List
from python_a2a import A2AServer, skill, agent, run_server

# Add paths for imports
common_agent_src = os.path.join(os.path.dirname(__file__), "..", "..", "common-agent", "src")
shared_path = os.path.join(os.path.dirname(__file__), "..", "..")
sys.path.insert(0, common_agent_src)
sys.path.insert(0, shared_path)

try:
    from mcp.simple_mcp_loader import SimpleMCPLoader
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    class SimpleMCPLoader:
        def __init__(self):
            pass
        def load_config(self):
            return {}
        def list_available_servers(self):
            return []
        def get_server_config(self, name):
            return None

try:
    from shared.config_manager import get_timeout
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    def get_timeout(timeout_type):
        # é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆ10åˆ†é’Ÿï¼‰
        return 600

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@agent(
    name="UIè®¾è®¡-å¤§å¤´",
    description="çœŸæ­£çš„LLMé©±åŠ¨UIè®¾è®¡ä¸“å®¶ï¼Œä½¿ç”¨çœŸå®MCPå·¥å…·è¿›è¡Œè®¾è®¡åˆ†æå’ŒåŸå‹åˆ¶ä½œ",
    version="1.0.0",
    url="http://localhost:8003",
    capabilities={
        "streaming": True,
        "google_a2a_compatible": True,
        "llm_powered": True,
        "real_mcp_integration": True,
        "no_simulation": True
    }
)
class RealUIDesignerAgent(A2AServer):
    """çœŸæ­£çš„UIè®¾è®¡å¸ˆAgent - å‚è€ƒcommon agentæ–¹å¼"""
    
    def __init__(self):
        super().__init__()
        self.agent_id = "real_ui_designer_agent"
        self.agent_name = "Real UI Designer Agent"
        
        # LLM APIé…ç½®
        self.api_key = os.getenv("SILICONFLOW_API_KEY", "xxxxx")
        self.base_url = "https://api.siliconflow.cn/v1"
        self.model = "deepseek-ai/DeepSeek-V3"
        
        # åˆå§‹åŒ–MCPç®¡ç†å™¨ - å‚è€ƒcommon agentæ–¹å¼
        self.mcp_loader = SimpleMCPLoader()
        self.available_mcp_servers = {}
        self.mcp_servers_info = {}
        
        self._init_mcp_system()
        
        logger.info("âœ… Real UI Designer Agent åˆå§‹åŒ–å®Œæˆ")
    
    def _init_mcp_system(self):
        """åˆå§‹åŒ–MCPç³»ç»Ÿï¼Œå‚è€ƒcommon agentæ–¹å¼"""
        try:
            # åŠ è½½mcp_servers.jsoné…ç½®
            self.available_mcp_servers = self.mcp_loader.load_config()
            
            available_servers = self.mcp_loader.list_available_servers()
            logger.info(f"ğŸ”§ ä»mcp_servers.jsonåŠ è½½ {len(available_servers)} ä¸ªMCPæœåŠ¡å™¨")
            
            # è®°å½•æ‰€æœ‰å¯ç”¨çš„MCPæœåŠ¡å™¨ä¿¡æ¯ç»™LLMä½¿ç”¨
            for server_name in available_servers:
                server_config = self.mcp_loader.get_server_config(server_name)
                if server_config:
                    self.mcp_servers_info[server_name] = {
                        "name": server_name,
                        "description": server_config.get('description', 'No description'),
                        "command": server_config.get('command', 'unknown'),
                        "status": "available_for_llm_decision"
                    }
                    logger.info(f"  ğŸ“‹ {server_name}: {server_config.get('description', '')}")
            
            logger.info(f"âœ… MCPç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œ{len(self.mcp_servers_info)} ä¸ªæœåŠ¡å™¨å¯ç”¨")
            
        except Exception as e:
            logger.error(f"âŒ MCPç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­è¿è¡Œï¼Œä½†æ²¡æœ‰MCPå·¥å…·
            self.mcp_servers_info = {}

    async def call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMè¿›è¡Œè®¾è®¡å†³ç­–"""
        try:
            async with httpx.AsyncClient(timeout=get_timeout("llm_api")) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 2000,
                        "temperature": 0.7
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result["choices"][0]["message"]["content"]
                else:
                    logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    return f"LLM APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                    
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¼‚å¸¸: {e}")
            return f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"

    def _format_mcp_info_for_llm(self) -> str:
        """æ ¼å¼åŒ–MCPæœåŠ¡å™¨ä¿¡æ¯ç»™LLM"""
        if not self.mcp_servers_info:
            return "æš‚æ— å¯ç”¨çš„MCPæœåŠ¡å™¨"
        
        mcp_info = ["æˆ‘æœ‰ä»¥ä¸‹çœŸå®çš„MCPæœåŠ¡å™¨å¯ç”¨ï¼š"]
        for server_name, info in self.mcp_servers_info.items():
            mcp_info.append(f"- {server_name}: {info['description']}")
        
        mcp_info.append("\næ³¨æ„ï¼šä½ å¯ä»¥å†³ç­–ä½¿ç”¨è¿™äº›MCPæœåŠ¡å™¨ä¸­çš„ä»»ä½•å·¥å…·æ¥å®Œæˆè®¾è®¡ä»»åŠ¡ã€‚")
        return "\n".join(mcp_info)

    @skill(
        name="LLMé©±åŠ¨çš„UIè®¾è®¡åˆ†æ",
        description="è®©LLMåˆ†æè®¾è®¡éœ€æ±‚å¹¶å†³ç­–ä½¿ç”¨å“ªäº›MCPå·¥å…·",
        tags=["llm-powered", "ui-design", "real-tools", "no-simulation"]
    )
    async def llm_driven_ui_design_analysis(self, design_requirements: str, target_platform: str = "web"):
        """LLMé©±åŠ¨çš„UIè®¾è®¡åˆ†æ"""
        
        logger.info(f"ğŸ¨ LLMé©±åŠ¨çš„UIè®¾è®¡åˆ†æ: {design_requirements}")
        
        # æ„å»ºåŒ…å«çœŸå®MCPæœåŠ¡å™¨ä¿¡æ¯çš„æç¤º
        mcp_info = self._format_mcp_info_for_llm()
        
        analysis_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„UI/UXè®¾è®¡å¸ˆï¼Œæˆ‘éœ€è¦ä¸ºä»¥ä¸‹éœ€æ±‚è¿›è¡Œè®¾è®¡ï¼š

è®¾è®¡éœ€æ±‚ï¼š{design_requirements}
ç›®æ ‡å¹³å°ï¼š{target_platform}

{mcp_info}

è¯·åˆ†æè¿™ä¸ªè®¾è®¡ä»»åŠ¡ï¼Œå†³å®šéœ€è¦ä½¿ç”¨å“ªäº›MCPæœåŠ¡å™¨å’Œå·¥å…·æ¥å®Œæˆè®¾è®¡å·¥ä½œã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "design_analysis": "è®¾è®¡éœ€æ±‚åˆ†æ",
    "design_strategy": "è®¾è®¡ç­–ç•¥",
    "required_mcp_tools": [
        {{
            "server": "MCPæœåŠ¡å™¨åç§°",
            "purpose": "ä½¿ç”¨ç›®çš„",
            "design_task": "å…·ä½“è®¾è®¡ä»»åŠ¡",
            "expected_outcome": "é¢„æœŸäº§å‡º"
        }}
    ],
    "design_workflow": "è®¾è®¡å·¥ä½œæµç¨‹",
    "deliverables": ["äº¤ä»˜ç‰©åˆ—è¡¨"]
}}

åªä½¿ç”¨åˆ—å‡ºçš„çœŸå®MCPæœåŠ¡å™¨ï¼Œä½ å¯ä»¥æ¨æ–­æ¯ä¸ªæœåŠ¡å™¨å¯èƒ½æä¾›çš„è®¾è®¡ç›¸å…³å·¥å…·ã€‚
"""

        # LLMåˆ†æè®¾è®¡éœ€æ±‚
        llm_analysis = await self.call_llm(analysis_prompt)
        logger.info(f"ğŸ§  LLMè®¾è®¡åˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(llm_analysis)} å­—ç¬¦")
        
        # è§£æLLMåˆ†æç»“æœ
        try:
            import re
            json_match = re.search(r'\{.*\}', llm_analysis, re.DOTALL)
            if json_match:
                analysis_result = json.loads(json_match.group())
            else:
                analysis_result = {"required_mcp_tools": [], "design_analysis": llm_analysis}
        except Exception as e:
            logger.warning(f"âš ï¸ LLMåˆ†æè§£æå¤±è´¥: {e}")
            analysis_result = {"required_mcp_tools": [], "design_analysis": llm_analysis}
        
        # éªŒè¯LLMå†³ç­–çš„å·¥å…·
        tool_execution_plan = []
        required_tools = analysis_result.get("required_mcp_tools", [])
        
        logger.info(f"ğŸ¯ LLMå†³ç­–ä½¿ç”¨ {len(required_tools)} ä¸ªè®¾è®¡å·¥å…·")
        
        for tool in required_tools:
            server = tool.get("server")
            if server in self.mcp_servers_info:
                tool_execution_plan.append({
                    "server": server,
                    "purpose": tool.get("purpose"),
                    "design_task": tool.get("design_task"),
                    "expected_outcome": tool.get("expected_outcome"),
                    "server_info": self.mcp_servers_info[server],
                    "status": "llm_decided_real_server",
                    "note": "LLMé€‰æ‹©äº†çœŸå®å­˜åœ¨çš„MCPæœåŠ¡å™¨"
                })
                logger.info(f"âœ… LLMé€‰æ‹©çœŸå®æœåŠ¡å™¨: {server} - {tool.get('purpose')}")
            else:
                logger.warning(f"âš ï¸ LLMé€‰æ‹©äº†ä¸å­˜åœ¨çš„æœåŠ¡å™¨: {server}")
        
        # LLMåŸºäºå·¥å…·è®¡åˆ’ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–¹æ¡ˆ
        if tool_execution_plan:
            design_prompt = f"""
åŸºäºMCPå·¥å…·ä½¿ç”¨è®¡åˆ’ï¼Œä¸º"{design_requirements}"ç”Ÿæˆè¯¦ç»†çš„UIè®¾è®¡æ–¹æ¡ˆï¼š

åˆ†æç»“æœï¼š
{json.dumps(analysis_result, ensure_ascii=False, indent=2)}

å·¥å…·æ‰§è¡Œè®¡åˆ’ï¼š
{json.dumps(tool_execution_plan, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸“ä¸šçš„UIè®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
1. è®¾è®¡ç†å¿µå’ŒåŸåˆ™
2. ç”¨æˆ·ç•Œé¢æ¶æ„
3. è§†è§‰è®¾è®¡è§„èŒƒ
4. äº¤äº’è®¾è®¡æ–¹æ¡ˆ
5. å“åº”å¼è®¾è®¡è€ƒè™‘
6. å¯è®¿é—®æ€§è®¾è®¡
7. å®ç°æŠ€æœ¯å»ºè®®

åŸºäºä¸“ä¸šè®¾è®¡çŸ¥è¯†å’ŒçœŸå®å·¥å…·èƒ½åŠ›ï¼Œæä¾›å¯æ‰§è¡Œçš„è®¾è®¡æ–¹æ¡ˆã€‚
"""

            final_design_plan = await self.call_llm(design_prompt)
        else:
            final_design_plan = "ç”±äºæ²¡æœ‰åˆé€‚çš„MCPå·¥å…·ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿè®¾è®¡æ–¹æ³•"
        
        return {
            "success": True,
            "design_requirements": design_requirements,
            "target_platform": target_platform,
            "llm_design_analysis": analysis_result,
            "tool_execution_plan": tool_execution_plan,
            "final_design_plan": final_design_plan,
            "methodology": "LLMä¸“ä¸šåˆ†æ + çœŸå®MCPå·¥å…·é›†æˆ + ä¸“ä¸šè®¾è®¡æ–¹æ¡ˆ",
            "tools_planned": len(tool_execution_plan),
            "message": f"âœ… å®ŒæˆåŸºäºLLMå†³ç­–çš„{design_requirements}UIè®¾è®¡åˆ†æ"
        }

    @skill(
        name="è®¾è®¡ç³»ç»Ÿæ¶æ„åˆ†æ",
        description="LLMåˆ†æè®¾è®¡ç³»ç»Ÿéœ€æ±‚å¹¶è§„åˆ’ç»„ä»¶æ¶æ„",
        tags=["design-system", "llm-analysis", "component-architecture"]
    )
    async def design_system_architecture(self, project_scope: str, design_requirements: List[str]):
        """è®¾è®¡ç³»ç»Ÿæ¶æ„åˆ†æ"""
        
        logger.info(f"ğŸ—ï¸ è®¾è®¡ç³»ç»Ÿæ¶æ„åˆ†æ: {project_scope}")
        
        # LLMåˆ†æè®¾è®¡ç³»ç»Ÿéœ€æ±‚
        mcp_info = self._format_mcp_info_for_llm()
        
        system_prompt = f"""
ä½œä¸ºèµ„æ·±çš„è®¾è®¡ç³»ç»Ÿæ¶æ„å¸ˆï¼Œè¯·ä¸ºä»¥ä¸‹é¡¹ç›®è®¾è®¡å®Œæ•´çš„è®¾è®¡ç³»ç»Ÿæ¶æ„ï¼š

é¡¹ç›®èŒƒå›´ï¼š{project_scope}
è®¾è®¡éœ€æ±‚ï¼š
{json.dumps(design_requirements, ensure_ascii=False, indent=2)}

{mcp_info}

è¯·åˆ¶å®šï¼š
1. è®¾è®¡ç³»ç»Ÿæ¶æ„
2. ç»„ä»¶å±‚çº§ç»“æ„
3. è®¾è®¡ä»¤ç‰Œè§„èŒƒ
4. MCPå·¥å…·ä½¿ç”¨ç­–ç•¥
5. ç»´æŠ¤å’Œæ‰©å±•è®¡åˆ’
6. å›¢é˜Ÿåä½œæµç¨‹

è¦æ±‚æ–¹æ¡ˆç§‘å­¦ã€å¯æ‰©å±•ã€åŸºäºçœŸå®MCPå·¥å…·èƒ½åŠ›ã€‚
"""

        architecture_plan = await self.call_llm(system_prompt)
        logger.info(f"ğŸ—ï¸ è®¾è®¡ç³»ç»Ÿæ¶æ„å®Œæˆ")
        
        return {
            "success": True,
            "project_scope": project_scope,
            "design_requirements": design_requirements,
            "architecture_plan": architecture_plan,
            "methodology": "LLMä¸“ä¸šæ¶æ„è®¾è®¡ + MCPå·¥å…·é›†æˆç­–ç•¥",
            "approach": "AIé©±åŠ¨çš„è®¾è®¡ç³»ç»Ÿè§„åˆ’"
        }

    # @skill(
    #     name="MCPæœåŠ¡å™¨çŠ¶æ€æ£€æŸ¥",
    #     description="æ£€æŸ¥å½“å‰å¯ç”¨çš„MCPæœåŠ¡å™¨çŠ¶æ€",
    #     tags=["mcp-status", "system-check", "real-time"]
    # )
    # async def check_mcp_servers_status(self):
    #     """æ£€æŸ¥MCPæœåŠ¡å™¨çŠ¶æ€"""
        
    #     return {
    #         "success": True,
    #         "mcp_system_status": "loaded_from_config",
    #         "total_servers": len(self.mcp_servers_info),
    #         "server_details": self.mcp_servers_info,
    #         "config_source": "mcp_servers.json",
    #         "integration_method": "SimpleMCPLoaderæ–¹å¼",
    #         "message": f"âœ… MCPçŠ¶æ€: {len(self.mcp_servers_info)}ä¸ªæœåŠ¡å™¨ä»é…ç½®æ–‡ä»¶åŠ è½½"
    #     }


def main():
    """ä¸»å‡½æ•°"""
    port = int(os.environ.get("AGENT_PORT", 8002))
    
    agent_instance = RealUIDesignerAgent()
    logger.info(f"ğŸš€ å¯åŠ¨Real UI Designer Agentï¼Œç«¯å£: {port}")
    logger.info("ğŸ¨ æ­¤Agentå‚è€ƒcommon agentæ–¹å¼ï¼Œä»mcp_servers.jsonè¯»å–çœŸå®é…ç½®")
    logger.info("ğŸ¯ LLMå†³ç­–ä½¿ç”¨çœŸå®MCPå·¥å…·ï¼Œæ— ä»»ä½•ç¡¬ç¼–ç æˆ–æ¨¡æ‹Ÿæ•°æ®")
    run_server(agent_instance, host="0.0.0.0", port=port)


if __name__ == "__main__":
    main() 
